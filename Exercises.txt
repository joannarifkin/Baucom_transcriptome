1. SRA practice, plus command line navigation and exploration practice
	a. Find some transcriptome sequence data from a species of your choice on the SRA. Identify the different parts of the record: BioProject, BioSample, Experiment, Run, Accession. Identify what was sequenced, why, on what platform, what the layout was (single- vs paired-end), and what the read lengths were.

	b. Download the data. 
	Easy mode: download to your computer and move the files over manually. 
	Medium mode: download using SRAtools. Also, download a .csv file explaining what the samples are. (Poke around in the "send to" menu.)
	Hard mode: download using SRAtools in a SLURM script.

	c. Put the data somewhere sensible! Easy mode: make a directory in your home directory to hold this project, and set up a "raw data" or "raw sequence" directory within it. 
	Medium mode: make copies of your data. Then delete the copies. 
	Hard mode: get access to the Baucom lab allocations on /turbo (long-term storage) and /scratch (short-term storage of large files).

	d. Look at your data. How big is the file in bytes? What about in kilo-, mega-, and gigabytes? (Play around with ls -l and ls -lh. What do -l and -h stand for? Remember that you can append --help to most bash commands to get a list of options!) 
	Easy mode: What does a fastq file look like (use the "less" command), and what information is encoded in the different lines? How do you QC programs confirm the file is formatted correctly? What is the difference between a fastq and fasta file? What about fq and fa? 
	Medium mode: how much space does compression save? Explore the relative sizes of a fastq and fastq.gz file using gunzip and gzip!
	Hard mode: make a copy of one of the fastq.gz files, then truncate it to be a small file (10-20 lines). See what happens to the downtown if you break it in different places or use vi, awk, or sed to alter the set of characters used in different lines.
	
2. QC those data!
	a. Use FastQC and multiQC to learn more about the libraries. What's wrong with them?
	Easy mode: run the commands file-by-file.
	Hard mode: use a SLURM script to do the QC steps.

3. Trim the data!
	Take a look at the QC reports from the data you downloaded. Are there adapters? If so, do you want to trim them? Skim a few papers and discussion fora on the pros and cons of trimming for your desired use, and explain your decision. Use either Trim Galore or Trimmomatic to trim, if it's appropriate for your needs.
	
4. Alignments!
	a. Gotta align your reads to something. Find a reference genome you want to use, from the same or a related species. Or an unrelated species, I'm not the boss of you. 
	Easy mode: Download your genome and index it.
	Medium mode: What is a genome index? Why do we need to make them before aligning reads?
	
	b. Align a read or paired-end set of files.
	Easy mode: Run the alignment interactively.
	Medium mode: Edit the SLURM script to align your reads to your genome.
	
	c. Take a look at the output files. 
	Easy mode: Check out the logfiles from the Star or RSubreads run. What kinds of logfiles are there? What do they tell you about what you just did / tried to do? Did it work? What went well? What went poorly?
	Medium mode: Are they .sam or .bam files? What's the difference? How big are the files? 
	Hard mode: Look at the files using "less." Did that work? Try running the following commands: 
		
		module load Bioinformatics
		module load samtools/1.13-fwwss5n
		samtools -view [your_file].Aligned.out.bam | less
		
		What are those commands doing? Why might we need to use them?
		What is the structure of the alignment output file? What do the different 
